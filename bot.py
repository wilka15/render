import os
import base64
from io import BytesIO
from PIL import Image
from dotenv import load_dotenv

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler,
    CallbackQueryHandler, ContextTypes, filters
)

from openai import OpenAI

# ====== –ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª—é—á–µ–π ======
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

client = OpenAI(api_key=OPENAI_API_KEY)

# ====== –ü–∞–º—è—Ç—å ======
user_memory = {}
MAX_HISTORY = 10

# ====== –ö–Ω–æ–ø–∫–∏ ======
def main_keyboard():
    return InlineKeyboardMarkup([
        [InlineKeyboardButton("üßπ –û—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å", callback_data="clear"),
         InlineKeyboardButton("‚ÑπÔ∏è –û –±–æ—Ç–µ", callback_data="about")],
        [InlineKeyboardButton("üé® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É", callback_data="gen_image")]
    ])

# ====== /start ======
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø SmartAI-–±–æ—Ç! üé®\n"
        "–ü–∏—à–∏ –º–Ω–µ –∏–ª–∏ —É–ø–æ–º–∏–Ω–∞–π –º–µ–Ω—è –≤ –≥—Ä—É–ø–ø–µ —á–µ—Ä–µ–∑ @.",
        reply_markup=main_keyboard()
    )

# ====== –ö–Ω–æ–ø–∫–∏ ======
async def buttons(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    user_id = query.from_user.id

    if query.data == "clear":
        user_memory[user_id] = []
        await query.edit_message_text("üßπ –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞!")

    elif query.data == "about":
        await query.edit_message_text(
            "–Ø GPT-–±–æ—Ç —Å –ø–∞–º—è—Ç—å—é, –∫–Ω–æ–ø–∫–∞–º–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π üé®"
        )

    elif query.data == "gen_image":
        prompt = "–§–∞–Ω—Ç–∞—Å—Ç–∏—á–µ—Å–∫–∏–π –ø–µ–π–∑–∞–∂ –≤ —Å—Ç–∏–ª–µ —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –∏—Å–∫—É—Å—Å—Ç–≤–∞"
        try:
            response = client.images.generate(
                model="gpt-image-1",
                prompt=prompt,
                size="512x512"
            )
            image_url = response.data[0].url
            await query.message.reply_photo(photo=image_url, caption=f"–í–æ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∞ –ø–æ –ø—Ä–æ–º–ø—Ç—É:\n{prompt}")
        except Exception as e:
            await query.message.reply_text(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏: {e}")

# ====== –†–∞–±–æ—Ç–∞ —Å —Ç–µ–∫—Å—Ç–æ–º ======
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = update.message
    chat = message.chat
    text = message.text
    user_id = message.from_user.id
    bot_username = context.bot.username
    bot_id = context.bot.id

    # ===== –õ–æ–≥–∏–∫–∞ –≥—Ä—É–ø–ø =====
    if chat.type in ["group", "supergroup"]:
        mentioned = False
        if message.entities:
            for entity in message.entities:
                if entity.type == "mention":
                    mention_text = text[entity.offset: entity.offset + entity.length]
                    if mention_text.lower() == f"@{bot_username.lower()}":
                        mentioned = True
                        break
        replied_to_bot = (
            message.reply_to_message
            and message.reply_to_message.from_user
            and message.reply_to_message.from_user.id == bot_id
        )
        if not mentioned and not replied_to_bot:
            return
        text = text.replace(f"@{bot_username}", "").strip()

    # ===== –ü–∞–º—è—Ç—å =====
    history = user_memory.get(user_id, [])
    history.append({"role": "user", "content": text})
    history = history[-MAX_HISTORY:]

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π, —É–º–Ω—ã–π –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."},
                *history
            ],
            max_tokens=700
        )

        answer = response.choices[0].message.content
        history.append({"role": "assistant", "content": answer})
        user_memory[user_id] = history

        await message.reply_text(answer, reply_markup=main_keyboard())
    except Exception as e:
        await message.reply_text(f"–û—à–∏–±–∫–∞: {e}")

# ====== –†–∞–±–æ—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ ======
async def handle_image(update: Update, context: ContextTypes.DEFAULT_TYPE):
    photo = update.message.photo[-1]
    file = await photo.get_file()
    img_bytes = await file.download_as_bytearray()
    img = Image.open(BytesIO(img_bytes))

    buffered = BytesIO()
    img.save(buffered, format="PNG")
    b64_image = base64.b64encode(buffered.getvalue()).decode()

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": "–û–ø–∏—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ"},
                    {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{b64_image}"}}
                ]
            }],
            max_tokens=800
        )

        answer = response.choices[0].message.content
        await update.message.reply_text(answer, reply_markup=main_keyboard())
    except Exception as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º: {e}")

# ====== –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ======
def main():
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CallbackQueryHandler(buttons))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(MessageHandler(filters.PHOTO, handle_image))

    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
    app.run_polling()

if __name__ == "__main__":
    main()
